{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# o1js Benchmark\n",
        "\n",
        "This notebook benchmarks an MLP model implemented in PyTorch, which mirrors the structure of an MLP model defined using o1js in TypeScript. The model is then exported to ONNX format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install necessary packages\n",
        "!pip install torch numpy onnx ezkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import onnx\n",
        "import os\n",
        "import json\n",
        "import ezkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "exp_num = os.environ[\"EXP_NUM\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! mkdir -p mlp{exp_num}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_path = os.path.join(f'mlp{exp_num}/mlp.onnx')\n",
        "compiled_model_path = os.path.join(f'mlp{exp_num}/model.compiled')\n",
        "pk_path = os.path.join(f'mlp{exp_num}/pk.key')\n",
        "vk_path = os.path.join(f'mlp{exp_num}/test.vk')\n",
        "settings_path = os.path.join(f'mlp{exp_num}/settings.json')\n",
        "\n",
        "witness_path = os.path.join(f'mlp{exp_num}/witness.json')\n",
        "data_path = os.path.join('input.json')\n",
        "onnx_path =  os.path.join(f\"mlp{exp_num}/mlp.onnx\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the MLP Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the MLP class with the same structure as the o1js MLP\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, depth):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layers = nn.ModuleList([nn.Linear(5, 5) for _ in range(depth)])\n",
        "        self.output = nn.Linear(5, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                torch.nn.init.zeros_(m.weight.data)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = self.relu(layer(x))\n",
        "        x = self.output(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize the Model and Set Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the model\n",
        "depth = 2**int(exp_num)\n",
        "model = MLP(depth=depth)\n",
        "\n",
        "# Manually set the weights and biases to match the o1js example\n",
        "# with torch.no_grad():\n",
        "#     # `hidden1` expects a [1, 5] weight matrix for a [5] input vector\n",
        "#     model.hidden1.weight = nn.Parameter(torch.tensor([[2.0, 4.0, 3.0, 1.0, 5.0]]))  # shape [1, 5]\n",
        "#     model.hidden1.bias = nn.Parameter(torch.tensor([3.0]))  # shape [1]\n",
        "\n",
        "#     # `hidden2` expects a [1, 5] weight matrix for a [5] input vector (which is repeated 5 times)\n",
        "#     model.hidden2.weight = nn.Parameter(torch.tensor([[3.0, 1.0, 4.0, 2.0, 6.0]]))  # shape [1, 5]\n",
        "#     model.hidden2.bias = nn.Parameter(torch.tensor([2.0]))  # shape [1]\n",
        "\n",
        "#     # `output` expects a [1, 1] weight matrix for a [1] input vector\n",
        "#     model.output.weight = nn.Parameter(torch.tensor([[1.0]]))  # shape [1, 1]\n",
        "#     model.output.bias = nn.Parameter(torch.tensor([5.0]))  # shape [1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Perform Forward Pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create input data (same as in o1js example)\n",
        "# read in ./input_json\n",
        "data = json.load(open(\"input.json\", 'r'))\n",
        "\n",
        "# convert to torch tensor\n",
        "input_data = torch.tensor(data['input_data'], requires_grad=True)\n",
        "\n",
        "# Perform forward pass through the network\n",
        "output = model(input_data)\n",
        "print(\"Model Output:\", output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export the Model to ONNX Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export the model to ONNX format\n",
        "torch.onnx.export(\n",
        "    model,                          # Model being run\n",
        "    input_data,                     # Model input (or a tuple for multiple inputs)\n",
        "    onnx_path,                      # Where to save the model (can be a file or file-like object)\n",
        "    export_params=True,             # Store the trained parameter weights inside the model file\n",
        "    opset_version=10,               # The ONNX version to export the model to\n",
        "    do_constant_folding=True,       # Whether to execute constant folding for optimization\n",
        "    input_names=['input'],          # The model's input names\n",
        "    output_names=['output'],        # The model's output names\n",
        "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}  # Variable length axes\n",
        ")\n",
        "\n",
        "print(f\"Model exported to {onnx_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validate the ONNX Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and check the ONNX model\n",
        "onnx_model = onnx.load(onnx_path)\n",
        "onnx.checker.check_model(onnx_model)\n",
        "print('ONNX model is valid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Dictionary outputs\n",
        "res = ezkl.gen_settings(model_path, settings_path)\n",
        "assert res == True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# res = ezkl.calibrate_settings(data_path, model_path, settings_path, \"resources\")\n",
        "# assert res == True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
        "assert res == True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# srs path\n",
        "res = ezkl.get_srs(settings_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# now generate the witness file \n",
        "\n",
        "res = await ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
        "assert os.path.isfile(witness_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# HERE WE SETUP THE CIRCUIT PARAMS\n",
        "# WE GOT KEYS\n",
        "# WE GOT CIRCUIT PARAMETERS\n",
        "# EVERYTHING ANYONE HAS EVER NEEDED FOR ZK\n",
        "\n",
        "res = ezkl.setup(\n",
        "        compiled_model_path,\n",
        "        vk_path,\n",
        "        pk_path,\n",
        "        \n",
        "    )\n",
        "\n",
        "assert res == True\n",
        "assert os.path.isfile(vk_path)\n",
        "assert os.path.isfile(pk_path)\n",
        "assert os.path.isfile(settings_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
