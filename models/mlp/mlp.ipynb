{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# o1js Benchmark\n",
        "\n",
        "This notebook benchmarks an MLP model implemented in PyTorch, which mirrors the structure of an MLP model defined using o1js in TypeScript. The model is then exported to ONNX format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /Users/mac/.pyenv/versions/3.10.4/lib/python3.10/site-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /Users/mac/.pyenv/versions/3.10.4/lib/python3.10/site-packages (1.26.4)\n",
            "Requirement already satisfied: onnx in /Users/mac/.pyenv/versions/3.10.4/lib/python3.10/site-packages (1.16.2)\n",
            "Collecting ezkl\n",
            "  Using cached ezkl-12.0.1-cp37-abi3-macosx_10_12_x86_64.whl (11.9 MB)\n",
            "Requirement already satisfied: filelock in /Users/mac/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: jinja2 in /Users/mac/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: sympy in /Users/mac/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/mac/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /Users/mac/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from torch) (3.3)\n",
            "Requirement already satisfied: fsspec in /Users/mac/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /Users/mac/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from onnx) (4.25.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mac/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/mac/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: ezkl\n",
            "Successfully installed ezkl-12.0.1\n",
            "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.2 is available.\n",
            "You should consider upgrading via the '/Users/mac/.pyenv/versions/3.10.4/bin/python3.10 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "!pip install torch numpy onnx ezkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import onnx\n",
        "import os\n",
        "import json\n",
        "import ezkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "exp_num = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_path = os.path.join(f'mlp{exp_num}/mlp.onnx')\n",
        "compiled_model_path = os.path.join(f'mlp{exp_num}/model.compiled')\n",
        "pk_path = os.path.join(f'mlp{exp_num}/pk.key')\n",
        "vk_path = os.path.join(f'mlp{exp_num}/test.vk')\n",
        "settings_path = os.path.join(f'mlp{exp_num}/settings.json')\n",
        "\n",
        "witness_path = os.path.join(f'mlp{exp_num}/witness.json')\n",
        "data_path = os.path.join('input.json')\n",
        "onnx_path =  os.path.join(f\"mlp{exp_num}/mlp.onnx\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the MLP Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the MLP class with the same structure as the o1js MLP\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, depth):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layers = nn.ModuleList([nn.Linear(5, 5) for _ in range(depth)])\n",
        "        self.output = nn.Linear(5, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = self.relu(layer(x))\n",
        "        x = self.output(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize the Model and Set Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the model\n",
        "depth = 2**exp_num\n",
        "model = MLP(depth=depth)\n",
        "\n",
        "# Manually set the weights and biases to match the o1js example\n",
        "# with torch.no_grad():\n",
        "#     # `hidden1` expects a [1, 5] weight matrix for a [5] input vector\n",
        "#     model.hidden1.weight = nn.Parameter(torch.tensor([[2.0, 4.0, 3.0, 1.0, 5.0]]))  # shape [1, 5]\n",
        "#     model.hidden1.bias = nn.Parameter(torch.tensor([3.0]))  # shape [1]\n",
        "\n",
        "#     # `hidden2` expects a [1, 5] weight matrix for a [5] input vector (which is repeated 5 times)\n",
        "#     model.hidden2.weight = nn.Parameter(torch.tensor([[3.0, 1.0, 4.0, 2.0, 6.0]]))  # shape [1, 5]\n",
        "#     model.hidden2.bias = nn.Parameter(torch.tensor([2.0]))  # shape [1]\n",
        "\n",
        "#     # `output` expects a [1, 1] weight matrix for a [1] input vector\n",
        "#     model.output.weight = nn.Parameter(torch.tensor([[1.0]]))  # shape [1, 1]\n",
        "#     model.output.bias = nn.Parameter(torch.tensor([5.0]))  # shape [1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Perform Forward Pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Output: tensor([[0.4307],\n",
            "        [0.4307]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Create input data (same as in o1js example)\n",
        "# read in ./input_json\n",
        "data = json.load(open(\"input.json\", 'r'))\n",
        "\n",
        "# convert to torch tensor\n",
        "input_data = torch.tensor(data['input_data'], requires_grad=True)\n",
        "\n",
        "# Perform forward pass through the network\n",
        "output = model(input_data)\n",
        "print(\"Model Output:\", output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export the Model to ONNX Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model exported to mlp4/mlp.onnx\n"
          ]
        }
      ],
      "source": [
        "# Export the model to ONNX format\n",
        "torch.onnx.export(\n",
        "    model,                          # Model being run\n",
        "    input_data,                     # Model input (or a tuple for multiple inputs)\n",
        "    onnx_path,                      # Where to save the model (can be a file or file-like object)\n",
        "    export_params=True,             # Store the trained parameter weights inside the model file\n",
        "    opset_version=10,               # The ONNX version to export the model to\n",
        "    do_constant_folding=True,       # Whether to execute constant folding for optimization\n",
        "    input_names=['input'],          # The model's input names\n",
        "    output_names=['output'],        # The model's output names\n",
        "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}  # Variable length axes\n",
        ")\n",
        "\n",
        "print(f\"Model exported to {onnx_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validate the ONNX Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ONNX model is valid\n"
          ]
        }
      ],
      "source": [
        "# Load and check the ONNX model\n",
        "onnx_model = onnx.load(onnx_path)\n",
        "onnx.checker.check_model(onnx_model)\n",
        "print('ONNX model is valid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Dictionary outputs\n",
        "res = ezkl.gen_settings(model_path, settings_path)\n",
        "assert res == True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[72], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m res \u001b[38;5;241m=\u001b[39m ezkl\u001b[38;5;241m.\u001b[39mcalibrate_settings(data_path, model_path, settings_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresources\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m res \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "res = ezkl.calibrate_settings(data_path, model_path, settings_path, \"resources\")\n",
        "assert res == True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using 3 columns for non-linearity table.\n",
            "Using 3 columns for non-linearity table.\n",
            "Using 5 columns for non-linearity table.\n",
            "Using 5 columns for non-linearity table.\n",
            "Using 5 columns for non-linearity table.\n",
            "Using 5 columns for non-linearity table.\n"
          ]
        }
      ],
      "source": [
        "res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
        "assert res == True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "# srs path\n",
        "res = ezkl.get_srs(settings_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "# now generate the witness file \n",
        "\n",
        "res = await ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
        "assert os.path.isfile(witness_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using 3 columns for non-linearity table.\n",
            "Using 5 columns for non-linearity table.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using 5 columns for non-linearity table.\n",
            "value (15996785876420001792) out of range: (-1024, 1024)\n",
            "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
            "value (-53438638232309523938948110258632916992) out of range: (-1024, 1024)\n",
            "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
            "circuit creation from run args failed: TensorError(SigBitTruncationError)\n",
            "circuit creation from run args failed: TensorError(SigBitTruncationError)\n",
            "value (-53438638232309527038001114641837588480) out of range: (-2048, 2048)\n",
            "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
            "circuit creation from run args failed: TensorError(SigBitTruncationError)\n",
            "circuit creation from run args failed: TensorError(SigBitTruncationError)\n",
            "circuit creation from run args failed: TensorError(SigBitTruncationError)\n",
            "circuit creation from run args failed: TensorError(SigBitTruncationError)\n",
            "\n",
            "\n",
            " <------------- Numerical Fidelity Report (input_scale: 11, param_scale: 11, scale_input_multiplier: 1) ------------->\n",
            "\n",
            "+----------------+----------------+----------------+----------------+----------------+------------------+----------------+----------------+--------------------+--------------------+------------------------+\n",
            "| mean_error     | median_error   | max_error      | min_error      | mean_abs_error | median_abs_error | max_abs_error  | min_abs_error  | mean_squared_error | mean_percent_error | mean_abs_percent_error |\n",
            "+----------------+----------------+----------------+----------------+----------------+------------------+----------------+----------------+--------------------+--------------------+------------------------+\n",
            "| 0.000075399876 | 0.000075399876 | 0.000075399876 | 0.000075399876 | 0.000075399876 | 0.000075399876   | 0.000075399876 | 0.000075399876 | 0.0000000056851412 | 0.00017504752      | 0.00017504752          |\n",
            "+----------------+----------------+----------------+----------------+----------------+------------------+----------------+----------------+--------------------+--------------------+------------------------+\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# HERE WE SETUP THE CIRCUIT PARAMS\n",
        "# WE GOT KEYS\n",
        "# WE GOT CIRCUIT PARAMETERS\n",
        "# EVERYTHING ANYONE HAS EVER NEEDED FOR ZK\n",
        "\n",
        "\n",
        "\n",
        "res = ezkl.setup(\n",
        "        compiled_model_path,\n",
        "        vk_path,\n",
        "        pk_path,\n",
        "        \n",
        "    )\n",
        "\n",
        "assert res == True\n",
        "assert os.path.isfile(vk_path)\n",
        "assert os.path.isfile(pk_path)\n",
        "assert os.path.isfile(settings_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
